{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{SkyBlue}{\\text{Stadium Capacity Analysis}}$\n",
    "#### $\\color{SkyBlue}{\\text{Roman Lynch}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rule{27cm}{0.4pt}$\n",
    "### K-Means Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------#\n",
    "def dist(x1, x2):\n",
    "    return np.sqrt(np.sum(x1-x2)**2)\n",
    "#--------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------#\n",
    "def kMeans(df, k, tol=0.0005): \n",
    "    \"\"\"\n",
    "    Usage: input \n",
    "        df=data frame, \n",
    "        k=# of clusters\n",
    "        tol=tolerance for L_2 convergance check on centroids\n",
    "    \"\"\"    \n",
    "    #---------------------------------------#\n",
    "    #-- Initialize --#\n",
    "    clusters = np.zeros(len(df))\n",
    "\n",
    "    #-- k-means ++ --#\n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        # To intialize the centroids, we pick k datapoints (reliviley) evenly spaced from \n",
    "        # one another by Rank (due to rounding) #\n",
    "        data_point_rank_k = df[df['Rank'] == np.round((i+1)*(15/k), 0)]\n",
    "        centroids.append(data_point_rank_k.values[0])\n",
    "    centroids = np.vstack(centroids)\n",
    "    print(centroids)\n",
    "    #----------------#\n",
    "    \n",
    "    mean_error = np.inf\n",
    "    converged = False\n",
    "    \n",
    "    num_iterations = 0\n",
    "    \n",
    "    #---------------------------------------#\n",
    "    #-- LOOP UNTIL CONVERGENCE --#\n",
    "    while not(converged):\n",
    "        \n",
    "        #-- Cluster Assignment --#\n",
    "        for index, data in enumerate(df.values):\n",
    "            distances = [dist(data, centroid) for centroid in centroids]\n",
    "            clusters[index] = np.argmin(distances)\n",
    "        \n",
    "        #-- Update Centroids --#\n",
    "        updated_centroids = np.empty((k, df.shape[1]))\n",
    "        for index in range(k):\n",
    "            clust_data = df[clusters == index]\n",
    "            centroid = clust_data.mean(axis=0)\n",
    "            updated_centroids[index, :] = centroid\n",
    "            \n",
    "        #-- Calculate Meanerror --#\n",
    "        errors = []\n",
    "        for data, cluster in zip(df.values, clusters):\n",
    "            centroid = updated_centroids[int(cluster)]\n",
    "            errors.append(dist(data, centroid)**2)\n",
    "        \n",
    "        error_arr = np.array(errors)\n",
    "        \n",
    "        #-- Calculate Reconstruction Error --#\n",
    "        rec_err = np.sum(error_arr)/len(df)\n",
    "        \n",
    "        #-- Check for Convergence --#\n",
    "        if (abs(rec_err - mean_error) < tol):\n",
    "            converged = True\n",
    "#             print('Converged at iteration {} with a change of {}'.format(num_iterations, abs(rec_err - mean_error)))\n",
    "        \n",
    "        # Update Values\n",
    "        centroids = updated_centroids\n",
    "        mean_error = rec_err\n",
    "        num_iterations = num_iterations + 1\n",
    "        \n",
    "    #---------------------------------------#\n",
    "    return centroids, clusters, mean_error\n",
    "#--------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rule{27cm}{0.4pt}$ \n",
    "### Dataframe Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Team  Rank  Year       full_name abbreviation  arenacapacity\n",
      "0  Denver Nuggets     1  2023  Denver Nuggets          DEN            NaN\n",
      "1  Denver Nuggets     6  2022  Denver Nuggets          DEN            NaN\n",
      "2  Denver Nuggets     4  2021  Denver Nuggets          DEN            NaN\n",
      "3  Denver Nuggets     3  2020  Denver Nuggets          DEN            NaN\n",
      "4  Denver Nuggets     2  2019  Denver Nuggets          DEN            NaN\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------#\n",
    "# Creating the master data frame\n",
    "\n",
    "## Read in CSV files\n",
    "df_rankings = pd.read_csv(\"data/rankings.csv\")\n",
    "df_teams = pd.read_csv(\"data/team.csv\")\n",
    "df_team_details = pd.read_csv(\"data/team_details.csv\")\n",
    "\n",
    "## Only take important columns\n",
    "df_rankings = df_rankings[['Team', 'Rank', 'Year']]\n",
    "df_teams = df_teams[['full_name', 'abbreviation']]\n",
    "df_team_details = df_team_details[['abbreviation', 'arenacapacity']]\n",
    "\n",
    "## Clean \"*\" from all teams in df_rankings\n",
    "for i in range(len(df_rankings)):\n",
    "    if (df_rankings[\"Team\"].iloc[i].find('*')):\n",
    "        df_rankings[\"Team\"].iloc[i] = df_rankings[\"Team\"].iloc[i].replace('*', '')\n",
    "\n",
    "## Create the master dataframe by including year_founded, city, team, and rank\n",
    "df_master = pd.merge(df_rankings,df_teams, left_on=\"Team\", right_on=\"full_name\")\n",
    "df_master = pd.merge(df_master,df_team_details, left_on=\"abbreviation\", right_on =\"abbreviation\")\n",
    "#--------------------------------------------------------------------------------#\n",
    "\n",
    "print(df_master.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------#\n",
    "# Break the data up by year\n",
    "df_16 = df_master[df_master[\"Year\"] == 2016]\n",
    "df_17 = df_master[df_master[\"Year\"] == 2017]\n",
    "df_18 = df_master[df_master[\"Year\"] == 2018]\n",
    "df_19 = df_master[df_master[\"Year\"] == 2019]\n",
    "df_20 = df_master[df_master[\"Year\"] == 2020]\n",
    "df_21 = df_master[df_master[\"Year\"] == 2021]\n",
    "df_22 = df_master[df_master[\"Year\"] == 2022]\n",
    "df_23 = df_master[df_master[\"Year\"] == 2023]\n",
    "\n",
    "print(df_16.shape[0])\n",
    "print(df_17.shape[0])\n",
    "print(df_18.shape[0])\n",
    "print(df_19.shape[0])\n",
    "print(df_20.shape[0])\n",
    "print(df_21.shape[0])\n",
    "print(df_22.shape[0])\n",
    "print(df_23.shape[0])\n",
    "#--------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rule{27cm}{0.4pt}$ \n",
    "### Find optimal k value using 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15. nan]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m recon_errors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     centroids, clusters, reconstruction_error \u001b[38;5;241m=\u001b[39m \u001b[43mkMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_19\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marenacapacity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     recon_errors\u001b[38;5;241m.\u001b[39mappend(reconstruction_error)\n\u001b[0;32m     14\u001b[0m min_recon_errors_per_k\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmin(recon_errors))\n",
      "Cell \u001b[1;32mIn[4], line 47\u001b[0m, in \u001b[0;36mkMeans\u001b[1;34m(df, k, tol)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#-- Calculate Meanerror --#\u001b[39;00m\n\u001b[0;32m     46\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, cluster \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m, clusters):\n\u001b[0;32m     48\u001b[0m     centroid \u001b[38;5;241m=\u001b[39m updated_centroids[\u001b[38;5;28mint\u001b[39m(cluster)]\n\u001b[0;32m     49\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(dist(data, centroid)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:12284\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12210\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  12211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  12212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12213\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12214\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12282\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:1716\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m   1715\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m-> 1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome items were not contained in blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_values = [1,2,3,4,5,6,7,8,9,10]\n",
    "min_recon_errors_per_k = []\n",
    "\n",
    "# For all k-values, run k-means 10 times, keeping track of the minimum error found for\n",
    "# each value of k\n",
    "##################################################################################\n",
    "for k in k_values:\n",
    "    recon_errors = []\n",
    "    for _ in range(10):\n",
    "        centroids, clusters, reconstruction_error = kMeans(df_19[[\"Rank\", \"arenacapacity\"]], k)\n",
    "        \n",
    "        recon_errors.append(reconstruction_error)\n",
    "        \n",
    "    min_recon_errors_per_k.append(np.min(recon_errors))\n",
    "##################################################################################\n",
    "\n",
    "# Plotting the data\n",
    "plt.plot(k_values, min_recon_errors_per_k, marker='o')\n",
    "\n",
    "plt.xlabel('K-Values')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Simple Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we can see from the above elbow plot, k = 3 is an appropriate k-value to optimize run time while minimizing error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rule{27cm}{0.4pt}$ \n",
    "### Perform K-means with k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0000e+00 1.8064e+04]\n",
      " [1.0000e+01 1.8203e+04]\n",
      " [1.5000e+01 1.8104e+04]]\n",
      "[[5.0000e+00 2.0000e+04]\n",
      " [1.0000e+01 1.8694e+04]\n",
      " [1.5000e+01 1.8104e+04]]\n",
      "[[5.0000e+00 1.9060e+04]\n",
      " [1.0000e+01 1.8064e+04]\n",
      " [1.5000e+01 1.8104e+04]]\n",
      "[[5.0000e+00 1.8104e+04]\n",
      " [1.0000e+01 1.7791e+04]\n",
      " [1.5000e+01 1.8064e+04]]\n",
      "[[5.0000e+00 2.0000e+04]\n",
      " [1.0000e+01 1.9060e+04]\n",
      " [1.5000e+01 1.8422e+04]]\n",
      "[[5.0000e+00 1.7791e+04]\n",
      " [1.0000e+01 1.9060e+04]\n",
      " [1.5000e+01 1.8422e+04]]\n",
      "[[5.0000e+00 1.9060e+04]\n",
      " [1.0000e+01 1.7791e+04]\n",
      " [1.5000e+01 1.8422e+04]]\n",
      "[[5.000e+00 1.998e+04]\n",
      " [1.000e+01 2.100e+04]\n",
      " [1.500e+01 1.906e+04]]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------#\n",
    "## Use k-Means for clustering withk = 3\n",
    "centroids_23, clusters_23, mean_error_23 = kMeans(df_23[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_22, clusters_22, mean_error_22 = kMeans(df_22[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_21, clusters_21, mean_error_21 = kMeans(df_21[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_20, clusters_20, mean_error_20 = kMeans(df_20[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_19, clusters_19, mean_error_19 = kMeans(df_19[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_18, clusters_18, mean_error_18 = kMeans(df_18[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_17, clusters_17, mean_error_17 = kMeans(df_17[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "centroids_16, clusters_16, mean_error_16 = kMeans(df_16[[\"Rank\", \"arenacapacity\"]], k=3)\n",
    "#--------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#--------------------------------------------------------------------------------#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Organize output\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [\u001b[43mdf_16\u001b[49m, df_17, df_18, df_19, df_20, df_21, df_22, df_23]\n\u001b[0;32m      4\u001b[0m clusters \u001b[38;5;241m=\u001b[39m [clusters_16, clusters_17, clusters_18, clusters_19, clusters_20, clusters_21, clusters_22, clusters_23]\n\u001b[0;32m      5\u001b[0m years \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2016\u001b[39m, \u001b[38;5;241m2017\u001b[39m, \u001b[38;5;241m2018\u001b[39m, \u001b[38;5;241m2019\u001b[39m, \u001b[38;5;241m2020\u001b[39m, \u001b[38;5;241m2021\u001b[39m, \u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m2023\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_16' is not defined"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------#\n",
    "# Organize output\n",
    "dataframes = [df_16, df_17, df_18, df_19, df_20, df_21, df_22, df_23]\n",
    "clusters = [clusters_16, clusters_17, clusters_18, clusters_19, clusters_20, clusters_21, clusters_22, clusters_23]\n",
    "years = [2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "centroids = [centroids_16, centroids_17, centroids_18,centroids_19,centroids_20, centroids_21, centroids_22, centroids_23]\n",
    "#--------------------------------------------------------------------------------#\n",
    "\n",
    "#--------------------------------------------------------------------------------#\n",
    "# Plot the data\n",
    "\n",
    "## Initialize Plot\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 30), sharex=True)\n",
    "\n",
    "## Loop: Scatter Plot for each Year\n",
    "for i, (year, dataframe, cluster) in enumerate(zip(years, dataframes, clusters)):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(dataframe['Rank'], dataframe['arenacapacity'], c=cluster, marker='*', s=200)\n",
    "    ax.set_xlabel(\"Rank\")\n",
    "    ax.set_ylabel(\"Arena Capacity\")\n",
    "    ax.set_title(\"Scatter Plot for Year \" + str(year))\n",
    "    ## Plot centroids\n",
    "    ax.scatter(centroids[i][:, 0], centroids[i][:, 1], marker='X', s=200, c='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "#--------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rule{27cm}{0.4pt}$ \n",
    "### Analysis\n",
    "\n",
    "As evident by the above scatterplots, there does not appear to be a correlation between the capacity of the stadium and the final rank of an NBA team.\n",
    "\n",
    "Our origional hypothesis was that teams with stadiums of high capacity, have lots of fans. If you've ever heard the phrase \"Home team advantage,\" we wanted to see if more fans meant better performance.\n",
    "\n",
    "If this were to be the case we would see 3 discrete clusters.\n",
    "1. High rank, high capacity\n",
    "2. Medium rank, medium capacity\n",
    "3. Low rank, low capacity.\n",
    "\n",
    "Instead, they are clustered by capacity, and rank does not appear to have an affect on the clusters. As a result, we can conclude that there is no correlation between the capacity of the stadium and the final rank of an NBA team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
